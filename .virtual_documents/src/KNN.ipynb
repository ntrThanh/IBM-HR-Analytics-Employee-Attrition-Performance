


import pandas as pd





df = pd.read_csv('../Dataset/archive/WA_Fn-UseC_-HR-Employee-Attrition.csv')


df


X = df.drop(['Attrition', 'EmployeeNumber'], axis=1)
y = df['Attrition']


print(f'Số bản ghi dữ liệu: {len(X)}')
print(f'Số cột dữ liệu (tập X): {len(X.columns)}')


X


y





X_origin = X.copy()
y_origin = y.copy()


from sklearn.preprocessing import OneHotEncoder, LabelEncoder

# define model encoding
one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
label_encoder = LabelEncoder()


from sklearn.preprocessing import OneHotEncoder
import pandas as pd

# Giả sử X_origin là DataFrame ban đầu
encode_cols = [
    'BusinessTravel', 'Department', 'Education', 'EducationField',
    'EnvironmentSatisfaction', 'Gender', 'JobInvolvement', 'JobLevel',
    'JobRole', 'JobSatisfaction', 'MaritalStatus', 'Over18', 'OverTime',
    'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel',
    'WorkLifeBalance'
]
one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
# fit chuyển đổi luôn
X_encoded_array = one_hot_encoder.fit_transform(X_origin[encode_cols])

# Lấy tên cột mới sau khi mã hóa
encoded_columns = one_hot_encoder.get_feature_names_out(encode_cols)

# Tạo DataFrame từ mảng mã hóa
X_encoded_df = pd.DataFrame(X_encoded_array, columns=encoded_columns, index=X_origin.index)

# Gộp với phần dữ liệu còn lại
X_encode = pd.concat([X_origin.drop(columns=encode_cols), X_encoded_df], axis=1)


X_encode


y_encode = label_encoder.fit_transform(y_origin)


y_encode





import numpy as np
import warnings

warnings.filterwarnings('ignore')

class KNNClassifier:
    def __init__(self, n_neighbors):
        self.k = n_neighbors

    def fit(self, X_train, y_train):
        self.X_train = X_train
        if y_train.ndim > 1:
             self.y_train = y_train.flatten()
        else:
             self.y_train = y_train

    def _predict_single(self, x_test_sample):
        distances = np.linalg.norm(self.X_train - x_test_sample, axis=1)

        k_indices = np.argpartition(distances, self.k)[:self.k]

        k_neighbor_labels = self.y_train[k_indices]

        y_pred_avg = np.mean(k_neighbor_labels)

        if y_pred_avg >= 0.5:
            return 1
        else:
            return 0

    def predict(self, X_test):
        # Với mỗi x – unseen ở đầu vào (các phần tử trong tập Validation)
        y_preds = [self._predict_single(x) for x in X_test]
        return np.array(y_preds)


from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score

def find_best_k_and_evaluate_custom(X_train, y_train, X_test, y_test, description):
    print("="*60)
    print(f"ĐANG XỬ LÝ: {description}")

    # Các giá trị K cần thử (lấy số lẻ từ 1 đến 31)
    k_values_to_test = list(range(1, 32, 2))
    n_splits = 5 # Dùng 5-fold CV
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)

    k_f1_scores = {}

    # Vòng lặp qua từng giá trị K
    for k in k_values_to_test:
        fold_scores = []

        # Vòng lặp qua 5 fold
        for train_index, val_index in kf.split(X_train):
            X_cv_train, X_cv_val = X_train[train_index], X_train[val_index]
            y_cv_train, y_cv_val = y_train[train_index], y_train[val_index]

            # Huấn luyện mô hình KNN tự định nghĩa với K hiện tại
            model = KNNClassifier(n_neighbors=k)
            model.fit(X_cv_train, y_cv_train)
            y_cv_pred = model.predict(X_cv_val)

            # Tính F1-score (weighted) vì dữ liệu mất cân bằng
            score = f1_score(y_cv_val, y_cv_pred, average='weighted', zero_division=0)
            fold_scores.append(score)

        # Tính điểm F1 trung bình của K này
        k_f1_scores[k] = np.mean(fold_scores)

    # Tìm K có điểm F1 cao nhất
    best_k = max(k_f1_scores, key=k_f1_scores.get)
    print(f"\n>>> Giá trị K tốt nhất tìm được (qua CV) là: {best_k} <<<")

    final_model = KNNClassifier(n_neighbors=best_k)
    final_model.fit(X_train, y_train)

    y_pred = final_model.predict(X_test)

    if y_pred is not None:
        print(f"\n--- Kết quả trên tập TEST (với K={best_k}) ---")
        print(f"Độ chính xác (Accuracy): {accuracy_score(y_test, y_pred):.4f}")
        print("\nBáo cáo phân loại:\n", classification_report(y_test, y_pred, zero_division=0))
        print("\nMa trận nhầm lẫn:\n", confusion_matrix(y_test, y_pred))

    print("="*60 + "\n")


from sklearn.model_selection import GridSearchCV

def find_best_k_and_evaluate_sklearn(X_train, y_train, X_test, y_test, description):
    print("="*60)
    print(f"ĐANG XỬ LÝ (GridSearchCV): {description}")

    knn_model = KNeighborsClassifier()
    # Các giá trị K cần thử (lấy số lẻ từ 1 đến 31)
    param_grid = {'n_neighbors': list(range(1, 32, 2))}

    grid_search = GridSearchCV(
        knn_model,
        param_grid,
        cv=5,
        scoring='f1_weighted', # Rất quan trọng cho dữ liệu mất cân bằng
        n_jobs=-1
    )

    grid_search.fit(X_train, y_train)

    best_k = grid_search.best_params_['n_neighbors']

    # TỰ ĐỘNG huấn luyện lại trên toàn bộ X_train
    best_model = grid_search.best_estimator_

    print(f"\n>>> Giá trị K tốt nhất tìm được (qua CV) là: {best_k} <<<")

    print(f"\n--- Kết quả trên tập TEST (với K={best_k}) ---")
    y_pred = best_model.predict(X_test)

    print(f"Độ chính xác (Accuracy): {accuracy_score(y_test, y_pred):.4f}")
    print("\nBáo cáo phân loại:\n", classification_report(y_test, y_pred, zero_division=0))
    print("\nMa trận nhầm lẫn:\n", confusion_matrix(y_test, y_pred))
    print("="*60 + "\n")








from sklearn.model_selection import train_test_split

X_copy_encode = X_encode.copy()
y_copy_encode = y_encode.copy()


X_train_origin_t1, X_test_origin_t1, y_train_origin_t1, y_test_origin_t1 = train_test_split(
    X_encode, y_encode, test_size=0.2, random_state=42
)

X_train_origin_t2, X_test_origin_t2, y_train_origin_t2, y_test_origin_t2 = train_test_split(
    X_encode, y_encode, test_size=0.3, random_state=42
)

X_train_origin_t3, X_test_origin_t3, y_train_origin_t3, y_test_origin_t3 = train_test_split(
    X_encode, y_encode, test_size=0.4, random_state=42
)





find_best_k_and_evaluate_custom(
    X_train_origin_t1.to_numpy(),
    y_train_origin_t1,
    X_test_origin_t1.to_numpy(),
    y_test_origin_t1,
    "KNN (Numpy thuần) trên dữ liệu gốc chưa chuẩn hóa (train/test: 4/1)"
)


find_best_k_and_evaluate_custom(
    X_train_origin_t2.to_numpy(),
    y_train_origin_t2,
    X_test_origin_t2.to_numpy(),
    y_test_origin_t2,
    "KNN (Numpy thuần) trên dữ liệu gốc chưa chuẩn hóa (train/test: 7/3)"
)


find_best_k_and_evaluate_custom(
    X_train_origin_t3.to_numpy(),
    y_train_origin_t3,
    X_test_origin_t3.to_numpy(),
    y_test_origin_t3,
    "KNN (Numpy thuần) trên dữ liệu gốc chưa chuẩn hóa (train/test: 6/4)"
)





from sklearn.neighbors import KNeighborsClassifier


find_best_k_and_evaluate_sklearn(
    X_train_origin_t1, y_train_origin_t1,
    X_test_origin_t1, y_test_origin_t1,
    "KNN (Thư viện) trên dữ liệu gốc chưa chuẩn hóa (train/test: 4/1)"
)


find_best_k_and_evaluate_sklearn(
    X_train_origin_t2, y_train_origin_t2,
    X_test_origin_t2, y_test_origin_t2,
    "KNN (Thư viện) trên dữ liệu gốc chưa chuẩn hóa (train/test: 7/3)"
)


find_best_k_and_evaluate_sklearn(
    X_train_origin_t3, y_train_origin_t3,
    X_test_origin_t3, y_test_origin_t3,
    "KNN (Thư viện) trên dữ liệu gốc chưa chuẩn hóa (train/test: 6/4)"
)




















from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA

def run_pipeline(X_train, X_test, y_train, y_test,
                 continous_data,
                 n_components=None,
                 model_func=None,
                 title=None,
                 dim_reduction=None):
    X_train_std = X_train.copy()
    X_test_std = X_test.copy()

    # Xác định các cột liên tục có trong tập hiện tại
    cont_cols = [col for col in continous_data if col in X_train_std.columns]

    # Chuẩn hóa các cột liên tục
    scaler = StandardScaler()
    X_train_std[cont_cols] = scaler.fit_transform(X_train_std[cont_cols])
    X_test_std[cont_cols] = scaler.transform(X_test_std[cont_cols])

    if n_components is not None and dim_reduction:
        if dim_reduction.lower() == 'pca':
            reducer = PCA(n_components=n_components)
            X_train_std = reducer.fit_transform(X_train_std)
            X_test_std = reducer.transform(X_test_std)

        elif dim_reduction.lower() == 'lda':
            n_classes = len(set(y_train))
            max_components = min(n_components, n_classes - 1)

            reducer = LDA(n_components=max_components)
            X_train_std = reducer.fit_transform(X_train_std, y_train)
            X_test_std = reducer.transform(X_test_std)

    return model_func(X_train_std, y_train, X_test_std, y_test, title)


# Lấy data
X_pca = X_encode.copy()
y_pca = y_encode.copy()


continous_data = [
        'Age', 'DailyRate', 'DistanceFromHome', 'EmployeeCount',
        'HourlyRate', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',
        'PercentSalaryHike', 'StandardHours', 'TotalWorkingYears',
        'TrainingTimesLastYear', 'YearsAtCompany', 'YearsInCurrentRole',
        'YearsSinceLastPromotion', 'YearsWithCurrManager'
]


# Chia train/test
from sklearn.model_selection import train_test_split

X_train_t1_pca, X_test_t1_pca, y_train_t1_pca, y_test_t1_pca = train_test_split(X_pca, y_pca, test_size=0.2, random_state=42)
X_train_t2_pca, X_test_t2_pca, y_train_t2_pca, y_test_t2_pca = train_test_split(X_pca, y_pca, test_size=0.3, random_state=42)
X_train_t3_pca, X_test_t3_pca, y_train_t3_pca, y_test_t3_pca = train_test_split(X_pca, y_pca, test_size=0.4, random_state=42)





run_pipeline(
    X_train_t1_pca, X_test_t1_pca, y_train_t1_pca, y_test_t1_pca,
    continous_data,
    n_components=6,
    model_func=find_best_k_and_evaluate_custom,
    title="KNN (Numpy thuần) - PCA n=6 đã chuẩn hóa (train/test: 4/1)",
    dim_reduction='pca'
)


run_pipeline(
    X_train_t2_pca, X_test_t2_pca, y_train_t2_pca, y_test_t2_pca,
    continous_data,
    n_components=6,
    model_func=find_best_k_and_evaluate_custom,
    title="KNN (Numpy thuần) - PCA n=6 đã chuẩn hóa (train/test: 7/3)",
    dim_reduction='pca'
)


run_pipeline(
    X_train_t3_pca, X_test_t3_pca, y_train_t3_pca, y_test_t3_pca,
    continous_data,
    n_components=6,
    model_func=find_best_k_and_evaluate_custom,
    title="KNN (Numpy thuần) - PCA n=6 đã chuẩn hóa (train/test: 6/4)",
    dim_reduction='pca'
)





run_pipeline(
    X_train_t1_pca, X_test_t1_pca, y_train_t1_pca, y_test_t1_pca,
    continous_data,
    n_components=6,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN (Thư viện) - PCA n=6 đã chuẩn hóa (train/test: 4/1)",
    dim_reduction='pca'
)


run_pipeline(
    X_train_t2_pca, X_test_t2_pca, y_train_t2_pca, y_test_t2_pca,
    continous_data,
    n_components=6,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN (Thư viện) - PCA n=6 đã chuẩn hóa (train/test: 7/3)",
    dim_reduction='pca'
)


run_pipeline(
    X_train_t3_pca, X_test_t3_pca, y_train_t3_pca, y_test_t3_pca,
    continous_data,
    n_components=6,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN (Thư viện) - PCA n=6 đã chuẩn hóa (train/test: 6/4)",
    dim_reduction='pca'
)





# Lấy data
X_lda = X_encode.copy()
y_lda = y_encode.copy()


# Chia train/test
from sklearn.model_selection import train_test_split

X_train_t1_lda, X_test_t1_lda, y_train_t1_lda, y_test_t1_lda = train_test_split(X_lda, y_lda, test_size=0.2, random_state=42)
X_train_t2_lda, X_test_t2_lda, y_train_t2_lda, y_test_t2_lda = train_test_split(X_lda, y_lda, test_size=0.3, random_state=42)
X_train_t3_lda, X_test_t3_lda, y_train_t3_lda, y_test_t3_lda = train_test_split(X_lda, y_lda, test_size=0.4, random_state=42)





run_pipeline(
    X_train_t1_lda, X_test_t1_lda, y_train_t1_lda, y_test_t1_lda,
    continous_data,
    n_components=2,
    model_func=find_best_k_and_evaluate_custom,
    title="KNN (Numpy thuần) - LDA đã chuẩn hóa (train/test: 4/1)",
    dim_reduction='lda'
)


run_pipeline(
    X_train_t2_lda, X_test_t2_lda, y_train_t2_lda, y_test_t2_lda,
    continous_data,
    n_components=2,
    model_func=find_best_k_and_evaluate_custom,
    title="KNN (Numpy thuần) - LDA đã chuẩn hóa (train/test: 7/3)",
    dim_reduction='lda'
)


run_pipeline(
    X_train_t3_lda, X_test_t3_lda, y_train_t3_lda, y_test_t3_lda,
    continous_data,
    n_components=2,
    model_func=find_best_k_and_evaluate_custom,
    title="KNN (Numpy thuần) - LDA đã chuẩn hóa (train/test: 6/4)",
    dim_reduction='lda'
)





run_pipeline(
    X_train_t1_lda, X_test_t1_lda, y_train_t1_lda, y_test_t1_lda,
    continous_data,
    n_components=2,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN (Thư viện) - LDA đã chuẩn hóa (train/test: 4/1)",
    dim_reduction='lda'
)


run_pipeline(
    X_train_t2_lda, X_test_t2_lda, y_train_t2_lda, y_test_t2_lda,
    continous_data,
    n_components=2,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN (Thư viện) - LDA đã chuẩn hóa (train/test: 7/3)",
    dim_reduction='lda'
)


run_pipeline(
    X_train_t3_lda, X_test_t3_lda, y_train_t3_lda, y_test_t3_lda,
    continous_data,
    n_components=2,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN (Thư viện) - LDA đã chuẩn hóa (train/test: 6/4)",
    dim_reduction='lda'
)




















from matplotlib import pyplot as plt


def helper_and_plot(X, y, model=None, command='Default command',
           reduce_name=None, n_components=2, test_size=0.3, random_state=42):
    from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
    from sklearn.decomposition import PCA
    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
    from sklearn.preprocessing import StandardScaler
    from sklearn.model_selection import train_test_split
    import numpy as np
    import time

    # Danh sách các cột liên tục và phân loại
    continous_data = [
        'Age', 'DailyRate', 'DistanceFromHome', 'EmployeeCount',
        'HourlyRate', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',
        'PercentSalaryHike', 'StandardHours', 'TotalWorkingYears',
        'TrainingTimesLastYear', 'YearsAtCompany', 'YearsInCurrentRole',
        'YearsSinceLastPromotion', 'YearsWithCurrManager'
    ]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42
    )

    scaler = StandardScaler()
    X_train = X_train.copy()
    X_test = X_test.copy()

    cont_cols = [col for col in continous_data if col in X_train.columns]

    X_train[cont_cols] = scaler.fit_transform(X_train[cont_cols])
    X_test[cont_cols] = scaler.transform(X_test[cont_cols])

    if reduce_name == 'pca':
        model_rd = PCA(n_components=n_components)
        X_train = model_rd.fit_transform(X_train)
        X_test = model_rd.transform(X_test)
    elif reduce_name == 'lda':
        model_rd = LinearDiscriminantAnalysis(n_components=n_components)
        X_train = model_rd.fit_transform(X_train, y_train)
        X_test = model_rd.transform(X_test)

    start_time = time.time()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    end_time = time.time()


    def plot_prediction_vs_true(y_pred, y_test, title="So sánh Dự đoán và Thực tế"):
        y_pred = np.array(y_pred).flatten()
        y_test = np.array(y_test).flatten()

        plt.figure(figsize=(6, 4))
        x = np.arange(len(y_test))

        # Điểm đúng và sai
        correct = (y_pred == y_test)

        plt.scatter(x[correct], y_test[correct], color='green', label='Dự đoán đúng', marker='o')
        plt.scatter(x[~correct], y_test[~correct], color='red', label='Dự đoán sai', marker='x')

        plt.title(title, fontsize=14)
        plt.xlabel("Chỉ số mẫu (Index)")
        plt.ylabel("Nhãn (0/1)")
        plt.legend()
        plt.grid(True, linestyle='--', alpha=0.5)
        plt.tight_layout()
        plt.show()

    print()
    print('=' * 20, command, f'giữ lại {n_components} chiều', '=' * 20)
    print(f'X_train: {np.shape(X_train)}, X_test: {np.shape(X_test)}')
    print(f'Total time: {end_time - start_time:.4f}s')
    print(f'Accuracy of model {model.__class__.__name__}: {accuracy_score(y_test, y_pred):.4f}')
    print(f'Precision: {precision_score(y_test, y_pred):.4f}')
    print(f'Recall: {recall_score(y_test, y_pred):.4f}')
    print(f'F1-score: {f1_score(y_test, y_pred):.4f}')
    print(f'Confusion matrix:\n{confusion_matrix(y_test, y_pred)}')
    print('=' * 20, command, '=' * 20)
    print()

    plot_prediction_vs_true(y_pred, y_test)





model_knn = KNeighborsClassifier(n_neighbors=11)
X = X_encode.copy()
y = y_encode.copy()
helper_and_plot(X, y, model = model_knn, command = f'KNN (Numpy thuần, K={11}) - LDA đã chuẩn hóa (train/test: 6/4)', reduce_name = 'lda', n_components = 1, test_size=0.4, random_state=42)













