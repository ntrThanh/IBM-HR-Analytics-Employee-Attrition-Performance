


import warnings
warnings.filterwarnings("ignore")
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
import pandas as pd
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler





df = pd.read_csv('../Dataset/archive/WA_Fn-UseC_-HR-Employee-Attrition.csv')


df


X = df.drop(['Attrition', 'EmployeeNumber', 'Over18', 'EmployeeCount', 'StandardHours'], axis=1)
y = df['Attrition']


print(f'Số bản ghi dữ liệu: {len(X)}')
print(f'Số cột dữ liệu (tập X): {len(X.columns)}')


col_int32 = ['DailyRate', 'MonthlyIncome', 'MonthlyRate']
col_int16 = ['Age', 'DistanceFromHome', 'Education', 'EnvironmentSatisfaction', 'HourlyRate',
             'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'NumCompaniesWorked',
             'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction',
             'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',
             'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole',
             'YearsSinceLastPromotion', 'YearsWithCurrManager']

# ép kiểu
X[col_int32] = X[col_int32].astype('int32')
X[col_int16] = X[col_int16].astype('int16')

X_origin = X.copy()
y_origin = y.copy()

# One-hot cho các cột nominal
one_hot_encoder = OneHotEncoder(
    sparse_output=False,
    handle_unknown='ignore',
    drop='first'
)

encode_cols = [
    'BusinessTravel', 'Department', 'EducationField',
    'Gender', 'JobRole', 'MaritalStatus', 'OverTime'
]

X_encoded_array = one_hot_encoder.fit_transform(X_origin[encode_cols])
encoded_columns = one_hot_encoder.get_feature_names_out(encode_cols)

X_encoded_df = pd.DataFrame(
    X_encoded_array,
    columns=encoded_columns,
    index=X_origin.index
)

# Gộp data sau one-hot
X_encode = pd.concat([X_origin.drop(columns=encode_cols), X_encoded_df], axis=1)

# Encode y
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y_origin)

# Continuous columns cần scale
continuous_data = [
    'Age', 'DailyRate', 'DistanceFromHome', 'HourlyRate', 'MonthlyIncome',
    'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike',
    'TotalWorkingYears', 'TrainingTimesLastYear', 'YearsAtCompany',
    'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager'
]

# Standard Scaler
scaler = StandardScaler()
X_scaled_df = pd.DataFrame(
    scaler.fit_transform(X_encode[continuous_data]),
    columns=continuous_data,
    index=X_encode.index
).astype('float32')

# Gộp cùng dữ liệu còn lại
X_final = pd.concat(
    [
        X_encode.drop(columns=continuous_data),
        X_scaled_df
    ],
    axis=1
)

# One-hot columns cũng ép về float32
one_hot_cols = X_encoded_df.columns
X_final[one_hot_cols] = X_final[one_hot_cols].astype('float32')

# Có 2 loại dữ liệu là X_origin là X ban đầu đã được One Hot và X đã được làm sạch, chuẩn hóa.
# X = X_final
# X_origin = X_encode


print(f'Số bản ghi dữ liệu: {len(X)}')
print(f'Số cột dữ liệu (tập X): {len(X.columns)}')


X_encode.head()


y


y_encode = y.copy()





import numpy as np
import warnings

warnings.filterwarnings('ignore')

class KNNClassifier:
    def __init__(self, n_neighbors):
        self.k = n_neighbors

    def fit(self, X_train, y_train):
        self.X_train = X_train
        if y_train.ndim > 1:
             self.y_train = y_train.flatten()
        else:
             self.y_train = y_train

    def _predict_single(self, x_test_sample):
        distances = np.linalg.norm(self.X_train - x_test_sample, axis=1)

        k_indices = np.argpartition(distances, self.k)[:self.k]

        k_neighbor_labels = self.y_train[k_indices]

        y_pred_avg = np.mean(k_neighbor_labels)

        if y_pred_avg >= 0.5:
            return 1
        else:
            return 0

    def predict(self, X_test):
        # Với mỗi x – unseen ở đầu vào (các phần tử trong tập Validation)
        y_preds = [self._predict_single(x) for x in X_test]
        return np.array(y_preds)


from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score

def find_best_k_and_evaluate_custom(X_train, y_train, X_test, y_test, description):
    print("="*60)
    print(f"ĐANG XỬ LÝ: {description}")

    # Các giá trị K cần thử (lấy số lẻ từ 1 đến 31)
    k_values_to_test = list(range(1, 32, 2))
    n_splits = 5 # Dùng 5-fold CV
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)

    k_f1_scores = {}

    # Vòng lặp qua từng giá trị K
    for k in k_values_to_test:
        fold_scores = []

        # Vòng lặp qua 5 fold
        for train_index, val_index in kf.split(X_train):
            X_cv_train, X_cv_val = X_train[train_index], X_train[val_index]
            y_cv_train, y_cv_val = y_train[train_index], y_train[val_index]

            # Huấn luyện mô hình KNN tự định nghĩa với K hiện tại
            model = KNNClassifier(n_neighbors=k)
            model.fit(X_cv_train, y_cv_train)
            y_cv_pred = model.predict(X_cv_val)

            # Tính F1-score (weighted) vì dữ liệu mất cân bằng
            score = f1_score(y_cv_val, y_cv_pred, average='weighted', zero_division=0)
            fold_scores.append(score)

        # Tính điểm F1 trung bình của K này
        k_f1_scores[k] = np.mean(fold_scores)

    # Tìm K có điểm F1 cao nhất
    best_k = max(k_f1_scores, key=k_f1_scores.get)
    print(f"\n>>> Giá trị K tốt nhất tìm được (qua CV) là: {best_k} <<<")

    final_model = KNNClassifier(n_neighbors=best_k)
    final_model.fit(X_train, y_train)

    y_pred = final_model.predict(X_test)

    if y_pred is not None:
        print(f"\n--- Kết quả trên tập TEST (với K={best_k}) ---")
        print(f"Độ chính xác (Accuracy): {accuracy_score(y_test, y_pred):.4f}")
        print("\nBáo cáo phân loại:\n", classification_report(y_test, y_pred, zero_division=0))
        print("\nMa trận nhầm lẫn:\n", confusion_matrix(y_test, y_pred))

    print("="*60 + "\n")


from sklearn.model_selection import GridSearchCV

def find_best_k_and_evaluate_sklearn(X_train, y_train, X_test, y_test, description):
    print("="*60)
    print(f"ĐANG XỬ LÝ (GridSearchCV): {description}")

    knn_model = KNeighborsClassifier()
    # Các giá trị K cần thử (lấy số lẻ từ 1 đến 31)
    param_grid = {'n_neighbors': list(range(1, 32, 2))}

    grid_search = GridSearchCV(
        knn_model,
        param_grid,
        cv=5,
        scoring='f1_weighted', # Rất quan trọng cho dữ liệu mất cân bằng
        n_jobs=-1
    )

    grid_search.fit(X_train, y_train)

    best_k = grid_search.best_params_['n_neighbors']

    # TỰ ĐỘNG huấn luyện lại trên toàn bộ X_train
    best_model = grid_search.best_estimator_

    print(f"\n>>> Giá trị K tốt nhất tìm được (qua CV) là: {best_k} <<<")

    print(f"\n--- Kết quả trên tập TEST (với K={best_k}) ---")
    y_pred = best_model.predict(X_test)

    print(f"Độ chính xác (Accuracy): {accuracy_score(y_test, y_pred):.4f}")
    print("\nBáo cáo phân loại:\n", classification_report(y_test, y_pred, zero_division=0))
    print("\nMa trận nhầm lẫn:\n", confusion_matrix(y_test, y_pred))
    print("="*60 + "\n")


def find_best_k_and_evaluate(
    X_train, y_train,
    X_test, y_test,
    useSmote=False,
    description=""
):
    print("="*60)
    print(f"ĐANG XỬ LÝ (GridSearchCV): {description}")

    steps = []

    # 1. Scale (bắt buộc với KNN)
    steps.append(('scaler', StandardScaler()))

    # 2. SMOTE (nếu bật)
    if useSmote:
        steps.append((
            'smote',
            SMOTE(
                sampling_strategy=0.5,   # Khuyến nghị cho IBM HR
                random_state=42
            )
        ))

    # 3. KNN
    steps.append(('knn', KNeighborsClassifier()))

    pipe = Pipeline(steps)

    # Grid cho KNN (lưu ý: knn__n_neighbors)
    param_grid = {
        'knn__n_neighbors': list(range(1, 32, 2))
    }

    grid_search = GridSearchCV(
        pipe,
        param_grid,
        cv=5,
        scoring='f1_weighted',
        n_jobs=-1
    )

    grid_search.fit(X_train, y_train)

    best_k = grid_search.best_params_['knn__n_neighbors']
    best_model = grid_search.best_estimator_

    print(f"\n>>> Giá trị K tốt nhất: {best_k} <<<")

    print(f"\n--- Kết quả trên tập TEST ---")
    y_pred = best_model.predict(X_test)

    print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
    print("\nClassification Report:\n",
          classification_report(y_test, y_pred, zero_division=0))
    print("\nConfusion Matrix:\n",
          confusion_matrix(y_test, y_pred))

    print("="*60 + "\n")









from sklearn.model_selection import train_test_split

X_copy_encode = X_encode.copy()
y_copy_encode = y_encode.copy()


X_train_origin_t1, X_test_origin_t1, y_train_origin_t1, y_test_origin_t1 = train_test_split(
    X_copy_encode, y_copy_encode, test_size=0.2, random_state=42
)

X_train_origin_t2, X_test_origin_t2, y_train_origin_t2, y_test_origin_t2 = train_test_split(
    X_copy_encode, y_copy_encode, test_size=0.3, random_state=42
)

X_train_origin_t3, X_test_origin_t3, y_train_origin_t3, y_test_origin_t3 = train_test_split(
    X_copy_encode, y_copy_encode, test_size=0.4, random_state=42
)





find_best_k_and_evaluate_custom(
    X_train_origin_t1.to_numpy(),
    y_train_origin_t1,
    X_test_origin_t1.to_numpy(),
    y_test_origin_t1,
    "KNN (Numpy thuần) trên dữ liệu gốc chưa chuẩn hóa (train/test: 8/2)"
)


find_best_k_and_evaluate_custom(
    X_train_origin_t2.to_numpy(),
    y_train_origin_t2,
    X_test_origin_t2.to_numpy(),
    y_test_origin_t2,
    "KNN (Numpy thuần) trên dữ liệu gốc chưa chuẩn hóa (train/test: 7/3)"
)


find_best_k_and_evaluate_custom(
    X_train_origin_t3.to_numpy(),
    y_train_origin_t3,
    X_test_origin_t3.to_numpy(),
    y_test_origin_t3,
    "KNN (Numpy thuần) trên dữ liệu gốc chưa chuẩn hóa (train/test: 6/4)"
)





from sklearn.neighbors import KNeighborsClassifier


find_best_k_and_evaluate_sklearn(
    X_train_origin_t1, y_train_origin_t1,
    X_test_origin_t1, y_test_origin_t1,
    "KNN (Thư viện) trên dữ liệu gốc chưa chuẩn hóa (train/test: 8/2)"
)


find_best_k_and_evaluate_sklearn(
    X_train_origin_t2, y_train_origin_t2,
    X_test_origin_t2, y_test_origin_t2,
    "KNN (Thư viện) trên dữ liệu gốc chưa chuẩn hóa (train/test: 7/3)"
)


find_best_k_and_evaluate_sklearn(
    X_train_origin_t3, y_train_origin_t3,
    X_test_origin_t3, y_test_origin_t3,
    "KNN (Thư viện) trên dữ liệu gốc chưa chuẩn hóa (train/test: 6/4)"
)

















from sklearn.model_selection import train_test_split

X_final_copy = X_final.copy()
y_encode_copy = y_encode.copy()


X_train_origin_t1, X_test_origin_t1, y_train_origin_t1, y_test_origin_t1 = train_test_split(
    X_final_copy, y_encode_copy, test_size=0.2, random_state=42
)

X_train_origin_t2, X_test_origin_t2, y_train_origin_t2, y_test_origin_t2 = train_test_split(
    X_final_copy, y_encode_copy, test_size=0.3, random_state=42
)

X_train_origin_t3, X_test_origin_t3, y_train_origin_t3, y_test_origin_t3 = train_test_split(
    X_final_copy, y_encode_copy, test_size=0.4, random_state=42
)





find_best_k_and_evaluate_custom(
    X_train_origin_t1.to_numpy(),
    y_train_origin_t1,
    X_test_origin_t1.to_numpy(),
    y_test_origin_t1,
    "KNN (Numpy thuần) trên dữ liệu gốc đã chuẩn hóa (train/test: 8/2)"
)


find_best_k_and_evaluate_custom(
    X_train_origin_t2.to_numpy(),
    y_train_origin_t2,
    X_test_origin_t2.to_numpy(),
    y_test_origin_t2,
    "KNN (Numpy thuần) trên dữ liệu gốc đã chuẩn hóa (train/test: 7/3)"
)


find_best_k_and_evaluate_custom(
    X_train_origin_t3.to_numpy(),
    y_train_origin_t3,
    X_test_origin_t3.to_numpy(),
    y_test_origin_t3,
    "KNN (Numpy thuần) trên dữ liệu gốc chưa chuẩn hóa (train/test: 6/4)"
)





find_best_k_and_evaluate_sklearn(
    X_train_origin_t1, y_train_origin_t1,
    X_test_origin_t1, y_test_origin_t1,
    "KNN (Thư viện) trên dữ liệu gốc đã chuẩn hóa (train/test: 8/2)"
)


find_best_k_and_evaluate_sklearn(
    X_train_origin_t2, y_train_origin_t2,
    X_test_origin_t2, y_test_origin_t2,
    "KNN (Thư viện) trên dữ liệu gốc đã chuẩn hóa (train/test: 7/3)"
)


find_best_k_and_evaluate_sklearn(
    X_train_origin_t3, y_train_origin_t3,
    X_test_origin_t3, y_test_origin_t3,
    "KNN (Thư viện) trên dữ liệu gốc đã chuẩn hóa (train/test: 6/4)"
)











from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA

def run_pipeline(X_train, X_test, y_train, y_test,
                 continuous_data,
                 ordered_categorical_data,
                 n_components=None,
                 model_func=None,
                 title=None,
                 dim_reduction=None,
                 use_smote=False,
                sampling_strategy=0.5
                 ):
    X_train_std = X_train.copy()
    X_test_std = X_test.copy()

    # Xác định các cột liên tục có trong tập hiện tại
    cont_cols = [col for col in continuous_data if col in X_train_std.columns]

    # Xác định các cột categorical có thứ tự có trong tập hiện tại
    ordered_cat_cols = [col for col in ordered_categorical_data if col in X_train_std.columns]

    # Chuẩn hóa các cột liên tục
    scaler_cont = StandardScaler()
    if cont_cols:
        X_train_std[cont_cols] = scaler_cont.fit_transform(X_train_std[cont_cols])
        X_test_std[cont_cols] = scaler_cont.transform(X_test_std[cont_cols])

    # Chuẩn hóa các cột categorical có thứ tự
    scaler_ordered = StandardScaler()
    if ordered_cat_cols:
        X_train_std[ordered_cat_cols] = scaler_ordered.fit_transform(X_train_std[ordered_cat_cols])
        X_test_std[ordered_cat_cols] = scaler_ordered.transform(X_test_std[ordered_cat_cols])

    if n_components is not None and dim_reduction:
        if dim_reduction.lower() == 'pca':
            reducer = PCA(n_components=n_components)
            X_train_std = reducer.fit_transform(X_train_std)
            X_test_std = reducer.transform(X_test_std)

        elif dim_reduction.lower() == 'lda':
            n_classes = len(set(y_train))
            max_components = min(n_components, n_classes - 1)

            reducer = LDA(n_components=max_components)
            X_train_std = reducer.fit_transform(X_train_std, y_train)
            X_test_std = reducer.transform(X_test_std)

    if use_smote:
        smote = SMOTE(
            sampling_strategy=sampling_strategy,
            random_state=42
        )
        X_train_std, y_train = smote.fit_resample(X_train_std, y_train)

    return model_func(X_train_std, y_train, X_test_std, y_test, title)


continuous_data = [
    'Age', 'DailyRate', 'DistanceFromHome', 'HourlyRate', 'MonthlyIncome',
    'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike',
    'TotalWorkingYears', 'TrainingTimesLastYear', 'YearsAtCompany',
    'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager'
]
ordered_categorical_data = [
    'Education', 'Environment satisfaction', 'Job involvement', 'Job satisfaction', 'Performance rating', 'Relationship satisfaction', 'Work-life balance'
]





# Lấy data
X_pca = X_encode.copy()
y_pca = y_encode.copy()


# Chia train/test
from sklearn.model_selection import train_test_split

X_train_t1_pca, X_test_t1_pca, y_train_t1_pca, y_test_t1_pca = train_test_split(X_pca, y_pca, test_size=0.2, random_state=42)
X_train_t2_pca, X_test_t2_pca, y_train_t2_pca, y_test_t2_pca = train_test_split(X_pca, y_pca, test_size=0.3, random_state=42)
X_train_t3_pca, X_test_t3_pca, y_train_t3_pca, y_test_t3_pca = train_test_split(X_pca, y_pca, test_size=0.4, random_state=42)





run_pipeline(
    X_train_t1_pca, X_test_t1_pca, y_train_t1_pca, y_test_t1_pca,
    continuous_data,
    ordered_categorical_data,
    n_components=6,
    model_func=find_best_k_and_evaluate_custom,
    title="KNN (Numpy thuần) - PCA n=6 đã chuẩn hóa (train/test: 8/2)",
    dim_reduction='pca'
)


run_pipeline(
    X_train_t2_pca, X_test_t2_pca, y_train_t2_pca, y_test_t2_pca,
    continuous_data,
    ordered_categorical_data,
    n_components=6,
    model_func=find_best_k_and_evaluate_custom,
    title="KNN (Numpy thuần) - PCA n=6 đã chuẩn hóa (train/test: 7/3)",
    dim_reduction='pca'
)


run_pipeline(
    X_train_t3_pca, X_test_t3_pca, y_train_t3_pca, y_test_t3_pca,
    continuous_data,
    ordered_categorical_data,
    n_components=6,
    model_func=find_best_k_and_evaluate_custom,
    title="KNN (Numpy thuần) - PCA n=6 đã chuẩn hóa (train/test: 6/4)",
    dim_reduction='pca'
)





run_pipeline(
    X_train_t1_pca, X_test_t1_pca, y_train_t1_pca, y_test_t1_pca,
    continuous_data,
    ordered_categorical_data,
    n_components=6,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN (Thư viện) - PCA n=6 đã chuẩn hóa (train/test: 8/2)",
    dim_reduction='pca'
)


run_pipeline(
    X_train_t2_pca, X_test_t2_pca, y_train_t2_pca, y_test_t2_pca,
    continuous_data,
    ordered_categorical_data,
    n_components=6,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN (Thư viện) - PCA n=6 đã chuẩn hóa (train/test: 7/3)",
    dim_reduction='pca'
)


run_pipeline(
    X_train_t3_pca, X_test_t3_pca, y_train_t3_pca, y_test_t3_pca,
    continuous_data,
    ordered_categorical_data,
    n_components=6,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN (Thư viện) - PCA n=6 đã chuẩn hóa (train/test: 6/4)",
    dim_reduction='pca'
)





# Lấy data
X_lda = X_encode.copy()
y_lda = y_encode.copy()


# Chia train/test
from sklearn.model_selection import train_test_split

X_train_t1_lda, X_test_t1_lda, y_train_t1_lda, y_test_t1_lda = train_test_split(X_lda, y_lda, test_size=0.2, random_state=42)
X_train_t2_lda, X_test_t2_lda, y_train_t2_lda, y_test_t2_lda = train_test_split(X_lda, y_lda, test_size=0.3, random_state=42)
X_train_t3_lda, X_test_t3_lda, y_train_t3_lda, y_test_t3_lda = train_test_split(X_lda, y_lda, test_size=0.4, random_state=42)





run_pipeline(
    X_train_t1_lda, X_test_t1_lda, y_train_t1_lda, y_test_t1_lda,
    continuous_data,
    ordered_categorical_data,
    n_components=2,
    model_func=find_best_k_and_evaluate_custom,
    title="KNN (Numpy thuần) - LDA đã chuẩn hóa (train/test: 8/2)",
    dim_reduction='lda'
)


run_pipeline(
    X_train_t2_lda, X_test_t2_lda, y_train_t2_lda, y_test_t2_lda,
    continuous_data,
    ordered_categorical_data,
    n_components=2,
    model_func=find_best_k_and_evaluate_custom,
    title="KNN (Numpy thuần) - LDA đã chuẩn hóa (train/test: 7/3)",
    dim_reduction='lda'
)


run_pipeline(
    X_train_t3_lda, X_test_t3_lda, y_train_t3_lda, y_test_t3_lda,
    continuous_data,
    ordered_categorical_data,
    n_components=2,
    model_func=find_best_k_and_evaluate_custom,
    title="KNN (Numpy thuần) - LDA đã chuẩn hóa (train/test: 6/4)",
    dim_reduction='lda'
)





run_pipeline(
    X_train_t1_lda, X_test_t1_lda, y_train_t1_lda, y_test_t1_lda,
    continuous_data,
    ordered_categorical_data,
    n_components=2,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN (Thư viện) - LDA đã chuẩn hóa (train/test: 8/2)",
    dim_reduction='lda'
)


run_pipeline(
    X_train_t2_lda, X_test_t2_lda, y_train_t2_lda, y_test_t2_lda,
    continuous_data,
    ordered_categorical_data,
    n_components=2,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN (Thư viện) - LDA đã chuẩn hóa (train/test: 7/3)",
    dim_reduction='lda'
)


run_pipeline(
    X_train_t3_lda, X_test_t3_lda, y_train_t3_lda, y_test_t3_lda,
    continuous_data,
    ordered_categorical_data,
    n_components=2,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN (Thư viện) - LDA đã chuẩn hóa (train/test: 6/4)",
    dim_reduction='lda'
)























from sklearn.model_selection import train_test_split

X_final_copy = X_final.copy()
y_encode_copy = y_encode.copy()


X_train_origin_t1, X_test_origin_t1, y_train_origin_t1, y_test_origin_t1 = train_test_split(
    X_final_copy, y_encode_copy, test_size=0.2, random_state=42
)

X_train_origin_t2, X_test_origin_t2, y_train_origin_t2, y_test_origin_t2 = train_test_split(
    X_final_copy, y_encode_copy, test_size=0.3, random_state=42
)

X_train_origin_t3, X_test_origin_t3, y_train_origin_t3, y_test_origin_t3 = train_test_split(
    X_final_copy, y_encode_copy, test_size=0.4, random_state=42
)


find_best_k_and_evaluate(
    X_train_origin_t1, y_train_origin_t1,
    X_test_origin_t1, y_test_origin_t1,
    useSmote=True,
    description="KNN + SMOTE với dữ liệu gốc đã chuẩn hóa tỉ lệ 8/2"
)


find_best_k_and_evaluate(
    X_train_origin_t2, y_train_origin_t2,
    X_test_origin_t2, y_test_origin_t2,
    useSmote=True,
    description="KNN + SMOTE với dữ liệu gốc đã chuẩn hóa tỉ lệ 7/3"
)


find_best_k_and_evaluate(
    X_train_origin_t3, y_train_origin_t3,
    X_test_origin_t3, y_test_origin_t3,
    useSmote=True,
    description="KNN + SMOTE với dữ liệu gốc đã chuẩn hóa tỉ lệ 6/4"
)





# Lấy data
X_pca = X_encode.copy()
y_pca = y_encode.copy()
# Chia train/test
from sklearn.model_selection import train_test_split

X_train_t1_pca, X_test_t1_pca, y_train_t1_pca, y_test_t1_pca = train_test_split(X_pca, y_pca, test_size=0.2,
                                                                                random_state=42)
X_train_t2_pca, X_test_t2_pca, y_train_t2_pca, y_test_t2_pca = train_test_split(X_pca, y_pca, test_size=0.3,
                                                                                random_state=42)
X_train_t3_pca, X_test_t3_pca, y_train_t3_pca, y_test_t3_pca = train_test_split(X_pca, y_pca, test_size=0.4,
                                                                                random_state=42)


run_pipeline(
    X_train_t1_pca, X_test_t1_pca, y_train_t1_pca, y_test_t1_pca,
    continuous_data,
    ordered_categorical_data,
    n_components=6,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN + Smote (Thư viện) - PCA n=6 đã chuẩn hóa (train/test: 8/2)",
    dim_reduction='pca',
    use_smote=True,
    sampling_strategy=0.5
)


run_pipeline(
    X_train_t2_pca, X_test_t2_pca, y_train_t2_pca, y_test_t2_pca,
    continuous_data,
    ordered_categorical_data,
    n_components=6,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN + Smote  (Thư viện) - PCA n=6 đã chuẩn hóa (train/test: 7/3)",
    dim_reduction='pca',
    use_smote=True,
    sampling_strategy=0.5
)


run_pipeline(
    X_train_t3_pca, X_test_t3_pca, y_train_t3_pca, y_test_t3_pca,
    continuous_data,
    ordered_categorical_data,
    n_components=6,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN + Smote  (Thư viện) - PCA n=6 đã chuẩn hóa (train/test: 6/4)",
    dim_reduction='pca',
    use_smote=True,
    sampling_strategy=0.5
)





# Lấy data
X_lda = X_encode.copy()
y_lda = y_encode.copy()
# Chia train/test
from sklearn.model_selection import train_test_split

X_train_t1_lda, X_test_t1_lda, y_train_t1_lda, y_test_t1_lda = train_test_split(X_lda, y_lda, test_size=0.2,
                                                                                random_state=42)
X_train_t2_lda, X_test_t2_lda, y_train_t2_lda, y_test_t2_lda = train_test_split(X_lda, y_lda, test_size=0.3,
                                                                                random_state=42)
X_train_t3_lda, X_test_t3_lda, y_train_t3_lda, y_test_t3_lda = train_test_split(X_lda, y_lda, test_size=0.4,
                                                                                random_state=42)


run_pipeline(
    X_train_t1_lda, X_test_t1_lda, y_train_t1_lda, y_test_t1_lda,
    continuous_data,
    ordered_categorical_data,
    n_components=2,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN + Smote  (Thư viện) - LDA đã chuẩn hóa (train/test: 8/2)",
    dim_reduction='lda',
    use_smote=True,
    sampling_strategy=0.5
)


run_pipeline(
    X_train_t2_lda, X_test_t2_lda, y_train_t2_lda, y_test_t2_lda,
    continuous_data,
    ordered_categorical_data,
    n_components=2,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN + Smote  (Thư viện) - LDA đã chuẩn hóa (train/test: 7/3)",
    dim_reduction='lda',
    use_smote=True,
    sampling_strategy=0.5
)


run_pipeline(
    X_train_t3_lda, X_test_t3_lda, y_train_t3_lda, y_test_t3_lda,
    continuous_data,
    ordered_categorical_data,
    n_components=2,
    model_func=find_best_k_and_evaluate_sklearn,
    title="KNN + Smote  (Thư viện) - LDA đã chuẩn hóa (train/test: 6/4)",
    dim_reduction='lda',
    use_smote=True,
    sampling_strategy=0.5
)




















from matplotlib import pyplot as plt


def helper_and_plot(X, y, model=None, command='Default command',
           reduce_name=None, n_components=2, test_size=0.3, useSmote=False, sampling_strategy=0.5, random_state=42):
    from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
    from sklearn.decomposition import PCA
    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
    from sklearn.preprocessing import StandardScaler
    from sklearn.model_selection import train_test_split
    import numpy as np
    import time

    # Dữ liệu liên tục
    continuous_data = [
        'Age', 'DailyRate', 'DistanceFromHome', 'HourlyRate', 'MonthlyIncome',
        'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike',
        'TotalWorkingYears', 'TrainingTimesLastYear', 'YearsAtCompany',
        'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager'
    ]
    ordered_categorical_data = [
        'Education', 'Environment satisfaction', 'Job involvement',
        'Job satisfaction', 'Performance rating', 'Relationship satisfaction',
        'Work-life balance'
    ]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42
    )

    X_train = X_train.copy()
    X_test = X_test.copy()

    cont_cols = [col for col in continuous_data if col in X_train.columns]
    ordered_cat_cols = [col for col in ordered_categorical_data if col in X_train.columns]

    # Chuẩn hóa các cột liên tục
    scaler_cont = StandardScaler()
    if cont_cols:
        X_train[cont_cols] = scaler_cont.fit_transform(X_train[cont_cols])
        X_test[cont_cols] = scaler_cont.transform(X_test[cont_cols])

    # Chuẩn hóa các cột categorical có thứ tự
    scaler_ordered = StandardScaler()
    if ordered_cat_cols:
        X_train[ordered_cat_cols] = scaler_ordered.fit_transform(X_train[ordered_cat_cols])
        X_test[ordered_cat_cols] = scaler_ordered.transform(X_test[ordered_cat_cols])

    if reduce_name == 'pca':
        model_rd = PCA(n_components=n_components)
        X_train = model_rd.fit_transform(X_train)
        X_test = model_rd.transform(X_test)
    elif reduce_name == 'lda':
        model_rd = LinearDiscriminantAnalysis(n_components=n_components)
        X_train = model_rd.fit_transform(X_train, y_train)
        X_test = model_rd.transform(X_test)

    if useSmote:
        smote = SMOTE(
            sampling_strategy=sampling_strategy,
            random_state=42
        )
        X_train, y_train = smote.fit_resample(X_train, y_train)
    start_time = time.time()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    end_time = time.time()


    def plot_prediction_vs_true(y_pred, y_test, title="So sánh Dự đoán và Thực tế"):
        y_pred = np.array(y_pred).flatten()
        y_test = np.array(y_test).flatten()

        plt.figure(figsize=(6, 4))
        x = np.arange(len(y_test))

        # Điểm đúng và sai
        correct = (y_pred == y_test)

        plt.scatter(x[correct], y_test[correct], color='green', label='Dự đoán đúng', marker='o')
        plt.scatter(x[~correct], y_test[~correct], color='red', label='Dự đoán sai', marker='x')

        plt.title(title, fontsize=14)
        plt.xlabel("Chỉ số mẫu (Index)")
        plt.ylabel("Nhãn (0/1)")
        plt.legend()
        plt.grid(True, linestyle='--', alpha=0.5)
        plt.tight_layout()
        plt.show()

    print()
    print('=' * 20, command, f'giữ lại {n_components} chiều', '=' * 20)
    print(f'X_train: {np.shape(X_train)}, X_test: {np.shape(X_test)}')
    print(f'Total time: {end_time - start_time:.4f}s')
    print(f'Accuracy of model {model.__class__.__name__}: {accuracy_score(y_test, y_pred):.4f}')
    print(f'Precision: {precision_score(y_test, y_pred):.4f}')
    print(f'Recall: {recall_score(y_test, y_pred):.4f}')
    print(f'F1-score: {f1_score(y_test, y_pred):.4f}')
    print(f'Confusion matrix:\n{confusion_matrix(y_test, y_pred)}')
    print('=' * 20, command, '=' * 20)
    print()

    plot_prediction_vs_true(y_pred, y_test)


model_knn = KNeighborsClassifier(n_neighbors=11)
X = X_encode.copy()
y = y_encode.copy()
helper_and_plot(
    X, y, model = model_knn, command = f'KNN (Sklearn, K={11}) - LDA + Smote đã chuẩn hóa (train/test: 8/2)',
    reduce_name = 'lda', n_components = 1, test_size=0.2, useSmote=True, sampling_strategy=0.5, random_state=42
)













