





import pandas as pd
import numpy as np
import matplotlib.pyplot as plt





from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler
import pandas as pd
import numpy as np

df = pd.read_csv('../Dataset/archive/WA_Fn-UseC_-HR-Employee-Attrition.csv')

X = df.drop(['Attrition', 'EmployeeNumber', 'Over18', 'EmployeeCount', 'StandardHours'], axis=1)
y = df['Attrition']

col_int32 = ['DailyRate', 'MonthlyIncome', 'MonthlyRate']
col_int16 = ['Age', 'DistanceFromHome', 'Education', 'EnvironmentSatisfaction', 'HourlyRate', 
             'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'NumCompaniesWorked', 
             'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', 
             'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', 
             'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole', 
             'YearsSinceLastPromotion', 'YearsWithCurrManager']

# ép kiểu
X[col_int32] = X[col_int32].astype('int32')
X[col_int16] = X[col_int16].astype('int16')

X_origin = X.copy()
y_origin = y.copy()

# One-hot cho các cột nominal
one_hot_encoder = OneHotEncoder(
    sparse_output=False,
    handle_unknown='ignore',
    drop='first'
)

encode_cols = [
    'BusinessTravel', 'Department', 'EducationField',
    'Gender', 'JobRole', 'MaritalStatus', 'OverTime'
]

X_encoded_array = one_hot_encoder.fit_transform(X_origin[encode_cols])
encoded_columns = one_hot_encoder.get_feature_names_out(encode_cols)

X_encoded_df = pd.DataFrame(
    X_encoded_array, 
    columns=encoded_columns,
    index=X_origin.index
)

# Gộp data sau one-hot
X_encode = pd.concat([X_origin.drop(columns=encode_cols), X_encoded_df], axis=1)

# Encode y
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y_origin)

# Continuous columns cần scale
continuous_data = [
    'Age', 'DailyRate', 'DistanceFromHome', 'HourlyRate', 'MonthlyIncome',
    'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike',
    'TotalWorkingYears', 'TrainingTimesLastYear', 'YearsAtCompany',
    'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager'
]

# Standard Scaler
scaler = StandardScaler()
X_scaled_df = pd.DataFrame(
    scaler.fit_transform(X_encode[continuous_data]),
    columns=continuous_data,
    index=X_encode.index
).astype('float32')

# Gộp cùng dữ liệu còn lại
X_final = pd.concat(
    [
        X_encode.drop(columns=continuous_data), 
        X_scaled_df                       
    ],
    axis=1
)

# One-hot columns cũng ép về float32
one_hot_cols = X_encoded_df.columns
X_final[one_hot_cols] = X_final[one_hot_cols].astype('float32')

X = X_final



df





print("Kích thước dữ liệu:", df.shape)
print("\nThông tin dữ liệu:")
print(df.info())
print("\nThống kê mô tả:")
print(df.describe(include='all'))
print("\nGiá trị thiếu:")
print(df.isnull().sum())









df.describe(include='all')





plt.figure(figsize=(12, 6))
df.select_dtypes('number').boxplot()
plt.title("Phát hiện giá trị ngoại lai (Outliers)")
plt.xticks(rotation=45)
plt.show()


# Dữ liệu liên tục
continous_data = [
    'Age',
    'DailyRate',
    'DistanceFromHome',
    'EmployeeCount',
    'HourlyRate',
    'MonthlyIncome',
    'MonthlyRate',
    'NumCompaniesWorked',
    'PercentSalaryHike',
    'StandardHours',
    'TotalWorkingYears',
    'TrainingTimesLastYear',
    'YearsAtCompany',
    'YearsInCurrentRole',
    'YearsSinceLastPromotion',
    'YearsWithCurrManager'
]

# Dữ liệu phân loại
classified_data = [
    'BusinessTravel',
    'Department',
    'Education',
    'EducationField',
    'EnvironmentSatisfaction',
    'Gender',
    'JobInvolvement',
    'JobLevel',
    'JobRole',
    'JobSatisfaction',
    'MaritalStatus',
    'Over18',
    'OverTime',
    'PerformanceRating',
    'RelationshipSatisfaction',
    'StockOptionLevel',
    'WorkLifeBalance'
]





import math
cols_per_row = 3
rows = math.ceil(len(classified_data) / cols_per_row)
plt.figure(figsize=(16, 4 * rows))
for i, col in enumerate(classified_data, 1):
    plt.subplot(rows, cols_per_row, i)

    # Lấy dữ liệu và màu sắc ngẫu nhiên
    colors = plt.cm.tab20(np.linspace(0, 1, len(df[col].value_counts())))

    df[col].value_counts().plot(kind='bar', color=colors)

    plt.title(f"{col}", fontsize=11, fontweight='bold')
    plt.xlabel("")
    plt.ylabel("Số lượng", fontsize=9)
    plt.xticks(rotation=20, fontsize=9)
    plt.grid(axis='y', linestyle='--', alpha=0.5)

plt.tight_layout()
plt.show()








continuous_data = continous_data.copy()

cols_per_row = 3
rows = math.ceil(len(continuous_data) / cols_per_row)

plt.figure(figsize=(16, 4 * rows))

# Vẽ histogram cho từng biến
for i, col in enumerate(continuous_data, 1):
    plt.subplot(rows, cols_per_row, i)
    
    # Chọn màu tự động từ colormap
    color = plt.cm.viridis(np.random.rand())
    
    plt.hist(df[col].dropna(), bins=30, color=color, edgecolor='black', alpha=0.8)
    plt.title(f"{col}", fontsize=11, fontweight='bold')
    plt.xlabel("")
    plt.ylabel("Tần suất", fontsize=9)
    plt.grid(axis='y', linestyle='--', alpha=0.5)
    
plt.tight_layout()
plt.show()






import matplotlib.pyplot as plt

cols_to_drop = ['Attrition', 'EmployeeNumber', 'Over18', 'EmployeeCount', 'StandardHours']
corr = df.drop(columns=cols_to_drop, errors='ignore').corr(numeric_only=True)

# Vẽ biểu đồ
plt.figure(figsize=(12, 10))
plt.imshow(corr, cmap='coolwarm', interpolation='nearest')
plt.colorbar(label='Hệ số tương quan')

# Nhãn trục
plt.xticks(range(len(corr.columns)), corr.columns, rotation=45, ha='right', fontsize=10)
plt.yticks(range(len(corr.columns)), corr.columns, fontsize=10)
plt.title("Ma trận tương quan giữa các biến số (loại bỏ EmployeeNumber & Attrition)",
          fontsize=14, fontweight='bold', pad=20)

# Hiển thị giá trị hệ số
for i in range(len(corr.columns)):
    for j in range(len(corr.columns)):
        text = f"{corr.iloc[i, j]:.2f}"
        plt.text(j, i, text,
                 ha='center', va='center',
                 color='black' if abs(corr.iloc[i, j]) < 0.6 else 'white',
                 fontsize=8, fontweight='bold')

plt.grid(False)
plt.tight_layout()
plt.show()









X





from sklearn.decomposition import PCA

# giảm còn 6 chiều
pca = PCA(n_components = 6)

X_pca = pca.fit_transform(X)

# hiển thị dưới dạng dataframe
X_pca_df = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(6)])



X_pca_df





import itertools

def visualize_pairs(X):
    cols = X.columns
    pairs = list(itertools.combinations(cols, 2))
    
    n_cols = 3
    n_rows = int(np.ceil(len(pairs) / n_cols))
    
    plt.figure(figsize=(15, 4 * n_rows))
    cmap_colors = plt.cm.get_cmap('viridis')
    
    for idx, (x_col, y_col) in enumerate(pairs, 1):
        plt.subplot(n_rows, n_cols, idx)
        plt.scatter(X[x_col], X[y_col], alpha=0.6, s=25, color=cmap_colors(idx / len(pairs)))
        plt.xlabel(x_col, fontsize=10)
        plt.ylabel(y_col, fontsize=10)
        plt.title(f"{x_col} vs {y_col}", fontsize=11, fontweight='bold')
        plt.grid(alpha=0.25)
    
    plt.tight_layout()
    plt.show()
visualize_pairs(X_pca_df)



import itertools

def visualize_pairs(X, y=None):
    cols = X.columns
    pairs = list(itertools.combinations(cols, 2))
    
    n_cols = 3
    n_rows = int(np.ceil(len(pairs) / n_cols))
    
    plt.figure(figsize=(15, 4 * n_rows))

    if y is not None:
        classes = np.unique(y)
        colors = plt.cm.get_cmap('tab10', len(classes))
    
    for idx, (x_col, y_col) in enumerate(pairs, 1):
        plt.subplot(n_rows, n_cols, idx)
        
        if y is not None:
            # Vẽ từng class một để có chú thích (legend)
            for i, cls in enumerate(classes):
                mask = (y == cls)
                plt.scatter(
                    X.loc[mask, x_col],
                    X.loc[mask, y_col],
                    alpha=0.6, s=25,
                    color=colors(i),
                    label=str(cls)
                )
            plt.legend(title="Class", fontsize=8, title_fontsize=9)
        else:
            cmap_colors = plt.cm.get_cmap('viridis')
            plt.scatter(X[x_col], X[y_col],
                        alpha=0.6, s=25,
                        color=cmap_colors(idx / len(pairs)))
        
        plt.xlabel(x_col, fontsize=10)
        plt.ylabel(y_col, fontsize=10)
        plt.title(f"{x_col} vs {y_col}", fontsize=11, fontweight='bold')
        plt.grid(alpha=0.25)
    
    plt.tight_layout()
    plt.show()

visualize_pairs(X_pca_df, y)







print("Phương sai giải thích của từng thành phần chính:")
print(pca.explained_variance_ratio_)



explained_variance = pca.explained_variance_ratio_
cumulative_variance = explained_variance.cumsum()

for i, var in enumerate(explained_variance): 
    print(f"PC{i+1}: {var:.4f} ({cumulative_variance[i]:.4f} tích lũy)")



plt.figure(figsize=(8, 5))
plt.bar(range(1, len(explained_variance)+1), explained_variance, 
        alpha=0.7, color='skyblue', edgecolor='black', label='Tỷ lệ phương sai từng thành phần')
plt.plot(range(1, len(cumulative_variance)+1), cumulative_variance, 
         marker='o', color='orange', label='Phương sai tích lũy')
plt.xticks(np.arange(1, len(explained_variance)+1))
plt.xlabel('Thành phần chính (Principal Component)')
plt.ylabel('Tỷ lệ phương sai giải thích')
plt.title('Biểu đồ phương sai giải thích của PCA', fontweight='bold')
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()












X_continous_pca_df = df[continous_data]


X_continous_pca_df


from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

pca_pipeline = Pipeline([
    ('scaler', StandardScaler()),      
    ('pca', PCA(n_components=6))      
])

X_continous_pca = pca_pipeline.fit_transform(df[continous_data])
X_continous_pca_df = pd.DataFrame(X_continous_pca,
                                  columns=[f'PC{i+1}_continous' for i in range(6)])

# Lấy thông tin PCA đã được fit
pca = pca_pipeline.named_steps['pca']

# Tính phương sai giải thích
explained_variance = pca.explained_variance_ratio_
cumulative_variance = explained_variance.cumsum()

for i, var in enumerate(explained_variance): 
    print(f"PC{i+1}: {var:.4f} ({cumulative_variance[i]:.4f} tích lũy)")

# Vẽ biểu đồ
plt.figure(figsize=(7, 4))
plt.bar(range(1, 7), explained_variance, color='skyblue', edgecolor='black', label='Explained Variance')
plt.plot(range(1, 7), cumulative_variance, marker='o', color='orange', label='Cumulative Variance')
plt.title('Phương sai giải thích của 6 thành phần PCA', fontsize=12, fontweight='bold')
plt.xlabel('Thành phần chính (PC)')
plt.ylabel('Tỷ lệ phương sai')
plt.xticks(range(1, 7))
plt.legend()
plt.tight_layout()
plt.show()









X


y








from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

lda = LinearDiscriminantAnalysis(n_components = 1)
X_lda = lda.fit_transform(X, y)


X_lda


plt.figure(figsize=(8, 5))

plt.hist(X_lda[y == 0], bins=30, alpha=0.6, color='blue', label='Class 0')
plt.hist(X_lda[y == 1], bins=30, alpha=0.6, color='red', label='Class 1')

plt.title('Phân bố dữ liệu sau khi giảm chiều bằng LDA (1D)')
plt.xlabel('Giá trị trục LDA1')
plt.ylabel('Số lượng mẫu')
plt.legend()
plt.grid(alpha=0.3)
plt.show()





explained_var_ratio = lda.explained_variance_ratio_
print("Phương sai giải thích của từng thành phần LDA:", explained_var_ratio)
print("Tổng lượng thông tin được bảo tồn:", explained_var_ratio.sum())













