








import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
import time
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import warnings
warnings.filterwarnings("ignore")
from imblearn.over_sampling import SMOTE






class MyLogisticRegression:
    def __init__(self, eta=0.001, tol=1e-4, maxcount=1000, lamda=0.0):
        self.eta = eta
        self.tol = tol
        self.maxcount = maxcount
        self.lamda = lamda
        self.X = None
        self.y = None
        self.w = None

    def sigmoid(self, s):
        return 1 / (1 + np.exp(-s))

    def sigmoid_stable(self, s):
        if s >= 200:
            return 1
        if s <= -200:
            return 0
        return 1 / (1 + np.exp(-s))

    def calculate_w(self, X, y, w_init, eta, tol=1e-4, max_count=10000, lamda=0.0):
        w = [w_init]
        it = 0
        d = X.shape[1]
        N = X.shape[0]
        count = 0
        check_w_after = 20
        while count < max_count:
            mix_id = np.random.permutation(N)
            for i in mix_id:
                xi = X[i, :].reshape(d, 1)
                yi = y[i]
                zi = self.sigmoid_stable(np.dot(w[-1].T, xi))
                w_new = w[-1] + eta * ((yi - zi) * xi - lamda * w[-1]) # Hiệu chỉnh L2 ở đây!
                count += 1
                if count % check_w_after == 0:
                    if np.linalg.norm(w_new - w[-check_w_after]) < tol:
                        return w
                w.append(w_new)
        return w

    def fit(self, X, y):
        X = np.hstack((np.ones((X.shape[0], 1)), X))
        self.X = X
        self.y = y.reshape(-1, 1)
        d = X.shape[1]
        w_init = np.random.randn(d, 1)
        self.w = self.calculate_w(X, self.y, w_init, self.eta, self.tol, self.maxcount, self.lamda)[-1]

    def predict(self, X_test):
        X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test))
        y_pred = np.zeros(len(X_test))
        for i in range(len(X_test)):
            z = self.sigmoid_stable(np.dot(self.w.T, X_test[i]))
            y_pred[i] = 1 if z >= 0.5 else 0
        return y_pred









def test_logistic(X, y, command="", normalize=False, use_smote=False):
    results = []

    TEST_SIZES = [0.2, 0.3, 0.4]
    C_VALUES = [0.01, 0.1, 1.0, 10.0]
    MAX_ITERS = [200, 500]

    best_f1 = -1
    y_pred_best = None
    y_test_best = None

    for test_size in TEST_SIZES:
        for C in C_VALUES:
            for max_iter in MAX_ITERS:

                start_time = time.time()

                X_train, X_test, y_train, y_test = train_test_split(
                    X, y,
                    test_size=test_size,
                    random_state=42,
                    stratify=y
                )

                if normalize:
                    scaler = StandardScaler()
                    X_train = scaler.fit_transform(X_train)
                    X_test = scaler.transform(X_test)

                if use_smote:
                    smote = SMOTE(random_state=42)
                    X_train, y_train = smote.fit_resample(X_train, y_train)

                model = LogisticRegression(
                    C=C,
                    max_iter=max_iter,
                )
                model.fit(X_train, y_train)

                y_pred = model.predict(X_test)

                acc = accuracy_score(y_test, y_pred)
                precision = precision_score(y_test, y_pred, zero_division=0)
                recall = recall_score(y_test, y_pred, zero_division=0)
                f1 = f1_score(y_test, y_pred, zero_division=0)

                total_time = time.time() - start_time

                if f1 > best_f1:
                    best_f1 = f1
                    y_pred_best = y_pred
                    y_test_best = y_test

                results.append({
                    "normalize": normalize,
                    "use_smote": use_smote,
                    "test_size": test_size,
                    "C": C,
                    "max_iter": max_iter,
                    "accuracy": acc,
                    "precision": precision,
                    "recall": recall,
                    "f1": f1,
                    "time": total_time
                })

    return results, y_test_best, y_pred_best






def test_logistic_pca(X, y, command="", use_smote=False):
    results = []

    PCA_DIMS = [4, 5, 6]
    TEST_SIZES = [0.2, 0.3, 0.4]
    C_VALUES = [0.01, 0.1, 1.0, 10.0]
    MAX_ITERS = [200, 500]

    best_score = 0
    y_test_best = None
    y_pred_best = None
    best_config = None

    for n_pca in PCA_DIMS:
        for test_size in TEST_SIZES:
            for C in C_VALUES:
                for max_iter in MAX_ITERS:

                    start_time = time.time()

                    X_train, X_test, y_train, y_test = train_test_split(
                        X, y,
                        test_size=test_size,
                        random_state=42,
                        stratify=y
                    )

                    scaler = StandardScaler()
                    X_train = scaler.fit_transform(X_train)
                    X_test = scaler.transform(X_test)

                    if use_smote:
                        smote = SMOTE(random_state=42)
                        X_train, y_train = smote.fit_resample(X_train, y_train)

                    pca = PCA(n_components=n_pca, random_state=42)
                    X_train = pca.fit_transform(X_train)
                    X_test = pca.transform(X_test)

                    model = LogisticRegression(
                        C=C,
                        max_iter=max_iter,
                    )
                    model.fit(X_train, y_train)

                    y_pred = model.predict(X_test)

                    acc = accuracy_score(y_test, y_pred)
                    precision = precision_score(y_test, y_pred, zero_division=0)
                    recall = recall_score(y_test, y_pred, zero_division=0)
                    f1 = f1_score(y_test, y_pred, zero_division=0)

                    total_time = time.time() - start_time

                    if acc > best_score:
                        best_score = acc
                        y_test_best = y_test
                        y_pred_best = y_pred
                        best_config = (n_pca, test_size, C, max_iter)

                    results.append({
                        "pca_dim": n_pca,
                        "test_size": test_size,
                        "C": C,
                        "max_iter": max_iter,
                        "accuracy": acc,
                        "precision": precision,
                        "recall": recall,
                        "f1": f1,
                        "time": total_time
                    })

    print("Best config (PCA):", best_config)
    print("Best accuracy:", best_score)

    return results, y_test_best, y_pred_best






def test_logistic_lda(X, y, command="", use_smote=False):
    if len(np.unique(y)) != 2:
        raise ValueError("LDA chỉ áp dụng cho dữ liệu nhị phân (2 class).")

    results = []

    TEST_SIZES = [0.2, 0.3, 0.4]
    C_VALUES = [0.01, 0.1, 1.0, 10.0]
    MAX_ITERS = [200, 500]

    best_score = 0
    y_test_best = None
    y_pred_best = None
    best_config = None

    for test_size in TEST_SIZES:
        for C in C_VALUES:
            for max_iter in MAX_ITERS:

                start_time = time.time()

                X_train, X_test, y_train, y_test = train_test_split(
                    X, y,
                    test_size=test_size,
                    random_state=42,
                    stratify=y
                )

                scaler = StandardScaler()
                X_train = scaler.fit_transform(X_train)
                X_test = scaler.transform(X_test)

                if use_smote:
                    smote = SMOTE(random_state=42)
                    X_train, y_train = smote.fit_resample(X_train, y_train)

                lda = LinearDiscriminantAnalysis(n_components=1)
                X_train_lda = lda.fit_transform(X_train, y_train)
                X_test_lda = lda.transform(X_test)

                model = LogisticRegression(
                    C=C,
                    max_iter=max_iter,
                )
                model.fit(X_train_lda, y_train)

                y_pred = model.predict(X_test_lda)

                acc = accuracy_score(y_test, y_pred)
                precision = precision_score(y_test, y_pred, zero_division=0)
                recall = recall_score(y_test, y_pred, zero_division=0)
                f1 = f1_score(y_test, y_pred, zero_division=0)

                total_time = time.time() - start_time

                if acc > best_score:
                    best_score = acc
                    y_test_best = y_test
                    y_pred_best = y_pred
                    best_config = (test_size, C, max_iter)

                results.append({
                    "lda_dim": 1,
                    "test_size": test_size,
                    "C": C,
                    "max_iter": max_iter,
                    "accuracy": acc,
                    "precision": precision,
                    "recall": recall,
                    "f1": f1,
                    "time": total_time
                })

    print("Best config (LDA):", best_config)
    print("Best accuracy:", best_score)

    return results, y_test_best, y_pred_best






from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler
import pandas as pd
import numpy as np

df = pd.read_csv('../Dataset/archive/WA_Fn-UseC_-HR-Employee-Attrition.csv')

X = df.drop(['Attrition', 'EmployeeNumber', 'Over18', 'EmployeeCount', 'StandardHours'], axis=1)
y = df['Attrition']

col_int32 = ['DailyRate', 'MonthlyIncome', 'MonthlyRate']
col_int16 = ['Age', 'DistanceFromHome', 'Education', 'EnvironmentSatisfaction', 'HourlyRate',
             'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'NumCompaniesWorked',
             'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction',
             'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',
             'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole',
             'YearsSinceLastPromotion', 'YearsWithCurrManager']

# ép kiểu
X[col_int32] = X[col_int32].astype('int32')
X[col_int16] = X[col_int16].astype('int16')

X_origin = X.copy()
y_origin = y.copy()

# One-hot cho các cột nominal
one_hot_encoder = OneHotEncoder(
    sparse_output=False,
    handle_unknown='ignore',
    drop='first'
)

encode_cols = [
    'BusinessTravel', 'Department', 'EducationField',
    'Gender', 'JobRole', 'MaritalStatus', 'OverTime'
]

X_encoded_array = one_hot_encoder.fit_transform(X_origin[encode_cols])
encoded_columns = one_hot_encoder.get_feature_names_out(encode_cols)

X_encoded_df = pd.DataFrame(
    X_encoded_array,
    columns=encoded_columns,
    index=X_origin.index
)

# Gộp data sau one-hot
X_encode = pd.concat([X_origin.drop(columns=encode_cols), X_encoded_df], axis=1)

# Encode y
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y_origin)

# Continuous columns cần scale
continuous_data = [
    'Age', 'DailyRate', 'DistanceFromHome', 'HourlyRate', 'MonthlyIncome',
    'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike',
    'TotalWorkingYears', 'TrainingTimesLastYear', 'YearsAtCompany',
    'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager'
]

# Standard Scaler
scaler = StandardScaler()
X_scaled_df = pd.DataFrame(
    scaler.fit_transform(X_encode[continuous_data]),
    columns=continuous_data,
    index=X_encode.index
).astype('float32')

# Gộp cùng dữ liệu còn lại
X_final = pd.concat(
    [
        X_encode.drop(columns=continuous_data),
        X_scaled_df
    ],
    axis=1
)

# One-hot columns cũng ép về float32
one_hot_cols = X_encoded_df.columns
X_final[one_hot_cols] = X_final[one_hot_cols].astype('float32')

# Có 2 loại dữ liệu là X_origin là X ban đầu đã được One Hot và X đã được làm sạch, chuẩn hóa.
X = X_final
X_origin = X_encode


print(f'Số bản ghi dữ liệu: {len(X)}')
print(f'Số cột dữ liệu (tập X): {len(X.columns)}')


X_origin = X_origin.copy()
y_origin = y.copy()


X_encode.head()


y








result_origin, y_test, y_pred = test_logistic(X_origin, y, command = 'Dự đoán với dữ liệu ban đầu!')


df_origin = pd.DataFrame(result_origin)
df_origin.head()


df_origin_sorted = df_origin.sort_values(
    by=["accuracy", "precision", "f1", "recall"],
    ascending=[False, False, False, False]
)
df_origin_sorted.head(10)








result_origin_std, y_test_std, y_pred_std = test_logistic(X_origin, y, command = 'Dự đoán với dữ liệu ban đầu!', normalize = True)


df_origin_std = pd.DataFrame(result_origin_std)
df_origin_std.head()


df_origin_std_sorted = df_origin_std.sort_values(
    by=["accuracy", "precision", "f1", "recall"],
    ascending=[False, False, False, False]
)
df_origin_std_sorted.head(10)








result_pca, _, _ = test_logistic_pca(X_origin, y, command = 'Dự đoán với dữ liệu đã được giảm chiều bằng PCA!')


df_pca = pd.DataFrame(result_pca)
df_pca


df_pca_sorted = df_pca.sort_values(
    by=["accuracy", "precision", "f1", "recall"],
    ascending=[False, False, False, False]
)
df_pca_sorted.head(10)








result_lda, _, _ = test_logistic_lda(X_origin, y, command = 'Dự đoán với dữ liệu đã được giảm chiều bằng LDA!')


df_lda = pd.DataFrame(result_lda)
df_lda.head()


df_lda_sorted = df_lda.sort_values(
    by=["accuracy", "precision", "f1", "recall"],
    ascending=[False, False, False, False]
)
df_lda_sorted.head(10)











result_origin_std_smote, y_test_smote_std, y_pred_smote_std = test_logistic(X_origin, y, command = 'Dự đoán với dữ liệu ban đầu!', normalize = True, use_smote = True)
df_origin_std_smote = pd.DataFrame(result_origin_std_smote)
df_origin_std_smote.head()








result_pca_std_smote, _, _ = test_logistic_pca(X_origin, y, command = 'Dự đoán với dữ liệu LDA!', use_smote = True)
df_pca_std_smote = pd.DataFrame(result_pca_std_smote)
df_pca_std_smote.head()


df_pca_std_smote





result_lda_std_smote, _, _ = test_logistic_lda(X_origin, y, command = 'Dự đoán với dữ liệu PCA', use_smote = True)
df_lda_std_smote = pd.DataFrame(result_lda_std_smote)
df_lda_std_smote.head()


df_lda_std_smote














def plot_confusion_np(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)

    plt.imshow(cm)
    plt.colorbar()
    plt.xticks([0, 1], ["Pred 0", "Pred 1"])
    plt.yticks([0, 1], ["True 0", "True 1"])

    for i in range(2):
        for j in range(2):
            plt.text(j, i, cm[i, j],
                     ha="center", va="center")

    plt.title("Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()



plot_confusion_np(y_test_std, y_pred_std)








plot_confusion_np(y_test_smote_std, y_pred_smote_std)








def plot_multiple_series(series_dict, xlabel="", ylabel="", title="", figsize=(12, 6)):
    plt.figure(figsize=figsize)

    for label, series in series_dict.items():
        plt.plot(series.index, series.values, marker='o', label=label)

    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.title(title)
    plt.legend()
    plt.grid(True)
    plt.show()



plot_multiple_series(
    {
        "Result Origin": df_origin['accuracy'],
        "Result Origin STD": df_origin_std['accuracy'],
        "Result PCA": df_pca['accuracy'],
        "Result LDA": df_lda['accuracy'],
        "Result Origin STD SMOTE": df_origin_std_smote['accuracy'],
        "Result PCA SMOTE": df_pca_std_smote['accuracy'],
        "Result LDA SMOTE": df_lda_std_smote['accuracy']
    },
    xlabel="Experiment index",
    ylabel="Accuracy",
    title="Accuracy"
)





plot_multiple_series(
    {
        "Result Origin": df_origin['precision'],
        "Result Origin STD": df_origin_std['precision'],
        "Result PCA": df_pca['precision'],
        "Result LDA": df_lda['precision'],
        "Result Origin STD SMOTE": df_origin_std_smote['precision'],
        "Result PCA SMOTE": df_pca_std_smote['precision'],
        "Result LDA SMOTE": df_lda_std_smote['precision']
    },
    xlabel="Experiment index",
    ylabel="Precision",
    title="Precision"
)





plot_multiple_series(
    {
        "Result Origin": df_origin['recall'],
        "Result Origin STD": df_origin_std['recall'],
        "Result PCA": df_pca['recall'],
        "Result LDA": df_lda['recall'],
        "Result Origin STD SMOTE": df_origin_std_smote['recall'],
        "Result PCA SMOTE": df_pca_std_smote['recall'],
        "Result LDA SMOTE": df_lda_std_smote['recall']
    },
    xlabel="Experiment index",
    ylabel="Recall",
    title="Recall"
)





plot_multiple_series(
    {
        "Result Origin": df_origin['f1'],
        "Result Origin STD": df_origin_std['f1'],
        "Result PCA": df_pca['f1'],
        "Result LDA": df_lda['f1'],
        "Result Origin STD SMOTE": df_origin_std_smote['f1'],
        "Result PCA SMOTE": df_pca_std_smote['f1'],
        "Result LDA SMOTE": df_lda_std_smote['f1']
    },
    xlabel="Experiment index",
    ylabel="F1",
    title="F1"
)



